---
title: "Lesson06"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
root_path <- "C:/Git/RCourse_ML"
exerices_path <- file.path(root_path, "Exercises_and_Solutions")
```


```{r}
library(party)
```


```{r}
cfor_ctr <- cforest_unbiased(ntree = 500, mtry = 2)
rf.SepWid <- cforest(Sepal.Width~., data = iris, controls = cfor_ctr)
steps <- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.1)
predic <- matrix(NA, nrow=nrow(iris), ncol = length(steps))
for (i in 1:nrow(iris)){
obs <- iris[i,]
obs$Sepal.Width <- NULL # Remove column
for(s in 1:length(steps)){
obs$Sepal.Length <- steps[s]
predic[i,s] <- predict(rf.SepWid, newdata=obs)
}
}
```

```{r}
par(mfrow = c(2,1))
plot(NULL, xlim=c(min(iris$Sepal.Length), max(iris$Sepal.Length)),
  ylim=c(min(iris$Sepal.Width), max(iris$Sepal.Width)),
  xlab='Sepal.Length', ylab='Predicted Sepal.Width')
for(l in 1:nrow(predic)){
lines(x = steps, y = predic[l,], col=iris$Species[l])
}
lines(x=steps, y=apply(predic, 2, mean), col='gold2', lwd=6)
boxplot(Sepal.Length ~ Species, data = iris, horizontal = TRUE, col = 1:3)
par(mfrow = c(2,2))
```

## Exercise 1

```{r}
lesson_path <- file.path(exerices_path, "Lesson06_RandomForest")
```


load CSV
```{r}
dat <- read.csv(file.path(lesson_path, "rf_lm_data.csv"), stringsAsFactors = TRUE)
str(dat)
table(dat$pred_6)
```
Fixed split into training and test datasets
```{r}
set.seed(1241)
index <- sample(1:nrow(dat))
j2 <- nrow(dat) %*% 0.3 
index <- index[1:j2]
dat_tr <- dat[-index, ]
dat_te <- dat[index, ]
```


Linear model
```{r}
lm1 <- lm(y ~ ., data = dat_tr)
summary(lm1)
plot(lm1)
```




```{r}
cfor_ctr <- cforest_unbiased(ntree = 500, mtry = 2)
(rf1 <- cforest(y~., data = dat_tr, controls = cfor_ctr))
```


### Prediction

Linear model
```{r}
lm_pred <- predict(lm1, newdata = dat_te)
str(lm_pred)
```

RF model 
```{r}
rf_pred <- predict(rf1, newdat = dat_te)
str(rf_pred)
```

Calculate the RMSE for both models. 
The RMSE is the “root-mean-square-error” and is calculated by taking the differences between the predictions and the true y values, squaring them, taking the mean of the squared values and finally taking the square-root of the calculated mean value. The RMSE expresses how bad the predictions were, the larger the RMSE, the more imprecise were the predictions.

```{r}
dat_te <- cbind(dat_te, "ylm" = lm_pred, "yrf" = as.vector(rf_pred))
dat_te$er_lm <- dat_te$y - dat_te$ylm
dat_te$er_rf <- dat_te$y - dat_te$yrf

```

```{r}
rmse_lm <- sqrt(mean(dat_te$er_lm^2))
rmse_lm
rmse_rf <- sqrt(mean(dat_te$er_rf^2))
rmse_rf
```

```{r}
plot(NULL, xlim=c(min(dat_te$y), max(dat_te$y)),
  ylim=c(min(dat_te$ylm, dat_te$yrf), max(dat_te$ylm, dat_te$yrf)),
  xlab='y', ylab='y_hat', main="LM")
points(dat_te$y, dat_te$ylm, col=2)
# abline(a = 0, b = 1)
# plot(NULL, xlim=c(min(dat_te$y), max(dat_te$y)),
#   ylim=c(min(dat_te$ylm, dat_te$yrf), max(dat_te$ylm, dat_te$yrf)),
#   xlab='y', ylab='y_hat', main="RF")
points(dat_te$y, dat_te$yrf, col=4)
abline(a = 0, b = 1)

```



## Exercise 2

load CSV
```{r}
dat <- read.csv(file.path(lesson_path, "Wholesale_customers_data.csv"), stringsAsFactors = TRUE)
str(dat)
dat$Channel <- as.factor(dat$Channel)
dat$Channel <- as.factor(dat$Region)
table(dat$Channel, dat$Region)
```




```{r}
set.seed(294)
cfor_ctr <- cforest_unbiased(ntree = 500, mtry = 3) # use mtry = 3 becasue 1/2 of the number of predictors for classification 
(rf.whole <- cforest(Channel~., data = dat, controls = cfor_ctr))
```

confusion table
```{r}
(confT <- table(dat$Channel, predict(rf.whole, OOB = TRUE)))
diag(confT) <- 0
sum(confT)/nrow(dat)
```
```{r}
varimp(rf.whole)
```

#### Decision tree vs. RF

load crossVal function
```{r}
#*********************************************************************************
#   CV FUNCTION   ####
#*********************************************************************************
TREE_crossVal <- function(data, label, k_fold=10){
  stopifnot(nrow(data)==length(label), is.factor(label), 
            (1<k_fold & k_fold<=nrow(data)))
  # Create k sub-selections
  n <- nrow(data)
  ind_s <- sample(1:n)# mix up the order of the dataset
  ind.L <- list()
  j1 <- 1
  for (i in 1:k_fold){
    j2 <- (i*n) %/% k_fold # check 150 / 9 or 150 %/% 9
    ind.L[[i]] <- ind_s[j1:j2]
    j1 <- j2+1
  }
  # Now run KNN on each selection (and collect results):
  confMat <- matrix(0,nrow=nlevels(label), ncol=nlevels(label))
  for(fold in 1:k_fold){
    ind_fold <- ind.L[[fold]]

    trainDat <- data[-ind_fold,]
    testDat <- data[ind_fold,]
    trainSolu <- label[-ind_fold]
    testSolu <- label[ind_fold]
    
    dat.tr <- cbind(trainDat, "y"=trainSolu)
    ctree.pred <- party::ctree(y ~., data=dat.tr)


    pred.ctree <- predict(ctree.pred, newdata=testDat, type='response')
    confMat.fold <- table(pred.ctree, testSolu)

    confMat <- confMat + confMat.fold
  }
  # Calculate estimated test-error
  missMat <- confMat
  diag(missMat) <- 0
  missCount <- sum(missMat)
  test.err <- missCount/n
  L.res <- list(k_fold=k_fold, Indices=ind.L, 
                confMatrix=confMat, errorRate=test.err)
  return(L.res)
}

```


```{r}

TREE_crossVal(data = dat[,-1], label = dat[,1], k_fold = 10)

```
e) We want to get a better idea of the relation between the target variable Channel and the
Detergents_Paper variable. Can we already see a relation between the two variables when plotting
them against each other? Draw a boxplot comparing the Detergents_Paper values between the two
Channel levels.
```{r}
plot(Detergents_Paper~Channel, data = dat)
```











